{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2HhMfBcp5ziU",
        "37cpLg5Z56_G",
        "uU41SkLm6D4a",
        "XDD-nSWj6IaP",
        "inIGzi5B6Pec",
        "jQ12Gy_96VL8"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tugas 5 Deep Learning"
      ],
      "metadata": {
        "id": "t6CZzoJZ47Rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library dan Dataset"
      ],
      "metadata": {
        "id": "8JRhKQWQ-Vj6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4rZbf2645xH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "df_train = pd.read_csv('Train.csv')\n",
        "df_test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('Train.csv')\n",
        "df_test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "k1aSknQJ5KzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Praproses Data"
      ],
      "metadata": {
        "id": "2HhMfBcp5ziU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Atribut Kategorikal"
      ],
      "metadata": {
        "id": "37cpLg5Z56_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_missing_with_mode(df, columns):\n",
        "    for col in columns:\n",
        "        if col in df.columns:\n",
        "            mode_value = df[col].mode()[0]  # Menentukan modus\n",
        "            df[col] = df[col].fillna(mode_value)  # Mengisi missing values dengan modus\n",
        "        else:\n",
        "            print(f\"Kolom {col} tidak ditemukan dalam DataFrame.\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "CsJv9oHf53qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengisi null values pada kolom non numerik dengan value terbanyak dari masing masing atribut\n",
        "columns_to_fill = ['Ever_Married', 'Graduated', 'Profession', 'Var_1']\n",
        "df_train = fill_missing_with_mode(df_train, columns_to_fill)\n",
        "df_test = fill_missing_with_mode(df_test, columns_to_fill)"
      ],
      "metadata": {
        "id": "6etupdPW59SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Atribut Numerik"
      ],
      "metadata": {
        "id": "tmqnbk_U6AOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Periksa Karakteristik sebelum praproses"
      ],
      "metadata": {
        "id": "uU41SkLm6D4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_distribution(df, column):\n",
        "    if column in df.columns:\n",
        "        skewness = df[column].skew()  # Menghitung skewness\n",
        "        print(f\"Hasil: '{column}' = {skewness}\")\n",
        "\n",
        "        if skewness > 0:\n",
        "            return f\"Kolom '{column}' memiliki distribusi Right Skewed.\"\n",
        "        elif skewness < 0:\n",
        "            return f\"Kolom '{column}' memiliki distribusi Left Skewed.\"\n",
        "        else:\n",
        "            return f\"Kolom '{column}' memiliki distribusi normal.\"\n",
        "    else:\n",
        "        return f\"Kolom '{column}' tidak ditemukan.\""
      ],
      "metadata": {
        "id": "jq1nz4XI6BfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(check_distribution(df_train, 'Age'))\n",
        "print(check_distribution(df_train, 'Work_Experience'))\n",
        "print(check_distribution(df_train, 'Family_Size'))\n",
        "print(check_distribution(df_test, 'Age'))\n",
        "print(check_distribution(df_test, 'Work_Experience'))\n",
        "print(check_distribution(df_test, 'Family_Size'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFOFVi6q6H4V",
        "outputId": "7d41e4c5-25d0-4725-c0db-d2bb487ec128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil: 'Age' = 0.696020586305935\n",
            "Kolom 'Age' memiliki distribusi Right Skewed.\n",
            "Hasil: 'Work_Experience' = 1.3062257604935081\n",
            "Kolom 'Work_Experience' memiliki distribusi Right Skewed.\n",
            "Hasil: 'Family_Size' = 1.010804210772843\n",
            "Kolom 'Family_Size' memiliki distribusi Right Skewed.\n",
            "Hasil: 'Age' = 0.7044482403497572\n",
            "Kolom 'Age' memiliki distribusi Right Skewed.\n",
            "Hasil: 'Work_Experience' = 1.3886575371674614\n",
            "Kolom 'Work_Experience' memiliki distribusi Right Skewed.\n",
            "Hasil: 'Family_Size' = 1.0085039816076502\n",
            "Kolom 'Family_Size' memiliki distribusi Right Skewed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Praproses Atribut Numerik"
      ],
      "metadata": {
        "id": "XDD-nSWj6IaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_with_median(df, columns):\n",
        "    for col in columns:\n",
        "        if col in df.columns:\n",
        "            median_value = df[col].median()  # Mencari median\n",
        "            df[col] = df[col].fillna(median_value)  # Mengisi missing values dengan median\n",
        "        else:\n",
        "            print(f\"Kolom {col} tidak ditemukan dalam DataFrame.\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "_V03F5DD6KfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_fill = ['Age', 'Work_Experience', 'Family_Size']\n",
        "df_train = fill_with_median(df_train, columns_to_fill)\n",
        "df_test = fill_with_median(df_test, columns_to_fill)"
      ],
      "metadata": {
        "id": "ENmATfAp6Mbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Periksa Karakteristik Setelah Praproses"
      ],
      "metadata": {
        "id": "inIGzi5B6Pec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(check_distribution(df_train, 'Age'))\n",
        "print(check_distribution(df_train, 'Work_Experience'))\n",
        "print(check_distribution(df_train, 'Family_Size'))\n",
        "print(check_distribution(df_test, 'Age'))\n",
        "print(check_distribution(df_test, 'Work_Experience'))\n",
        "print(check_distribution(df_test, 'Family_Size'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NxsMvWu6SPD",
        "outputId": "a2a8b8c4-21ce-4e5b-e87f-aea1d062492a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil: 'Age' = 0.696020586305935\n",
            "Kolom 'Age' memiliki distribusi Right Skewed.\n",
            "Hasil: 'Work_Experience' = 1.4731291640065542\n",
            "Kolom 'Work_Experience' memiliki distribusi Right Skewed.\n",
            "Hasil: 'Family_Size' = 1.0194308941235437\n",
            "Kolom 'Family_Size' memiliki distribusi Right Skewed.\n",
            "Hasil: 'Age' = 0.7044482403497572\n",
            "Kolom 'Age' memiliki distribusi Right Skewed.\n",
            "Hasil: 'Work_Experience' = 1.5558779617827567\n",
            "Kolom 'Work_Experience' memiliki distribusi Right Skewed.\n",
            "Hasil: 'Family_Size' = 1.0753585877750917\n",
            "Kolom 'Family_Size' memiliki distribusi Right Skewed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pengubahan Data menjadi Tensor"
      ],
      "metadata": {
        "id": "jQ12Gy_96VL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_categorical_columns(df):\n",
        "  mappings = {}\n",
        "  for col in df.columns:\n",
        "    if df[col].dtypes == 'object':\n",
        "      label_dict = {k: i for i, k in enumerate(df[col].unique(), 0)}\n",
        "      mappings[col] = label_dict\n",
        "  return mappings"
      ],
      "metadata": {
        "id": "pv-k4ksW6YzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explore_clean_tensor(df,is_training=True):\n",
        "    mappings = map_categorical_columns(df)\n",
        "    \"\"\"\n",
        "    CONTOH HASIL:\n",
        "     mappings = {\n",
        "         'Gender': {'Male': 0, 'Female': 1},\n",
        "         'Ever_Married': {'No': 0, 'Yes': 1},\n",
        "         'Graduated': {'No': 0, 'Yes': 1},\n",
        "         'Profession': {\n",
        "             'Healthcare': 0, 'Engineer': 1, 'Lawyer': 2, 'Entertainment': 3,\n",
        "             'Artist': 4, 'Executive': 5, 'Doctor': 6, 'Homemaker': 7, 'Marketing': 8\n",
        "         },\n",
        "         'Spending_Score': {'Low': 0, 'Average': 1, 'High': 2},\n",
        "         'Var_1': {\n",
        "             'Cat_4': 0, 'Cat_6': 1, 'Cat_7': 2, 'Cat_3': 3,\n",
        "             'Cat_1': 4, 'Cat_2': 5, 'Cat_5': 6\n",
        "         },\n",
        "         'Segmentation': {'D': 0, 'A': 1, 'B': 2, 'C': 3}\n",
        "     }\n",
        "    \"\"\"\n",
        "    data = df\n",
        "       # map atribut kategorikal dengan mapping yang sudah dibuat\n",
        "    for col, map_dict in mappings.items():\n",
        "        if col in data.columns:\n",
        "            print(f\"Mapping column '{col}' with values: {map_dict}\")\n",
        "            data[col] = data[col].map(map_dict)\n",
        "\n",
        "    # memastikan seluruh data pada setiap atribut adalah numeric\n",
        "    for col in data.columns:\n",
        "        try:\n",
        "              pd.to_numeric(data[col])\n",
        "        except ValueError:\n",
        "            return f\"Error: Column '{col}' contains non-numeric values.\"\n",
        "\n",
        "    # memisahkan atribut yang digunakan untuk fitur dan target, dengan asumsi bahwa target selalu berada di kolom paling akhir\n",
        "    if is_training:\n",
        "        features = data.iloc[:, :-1]\n",
        "        target = data.iloc[:,-1:]\n",
        "    else:\n",
        "        features = data.iloc[:, :-1]\n",
        "        target = data.iloc[:, -1:]\n",
        "\n",
        "    # normalisasi fitur\n",
        "    scaler = StandardScaler()\n",
        "    features = scaler.fit_transform(features)\n",
        "\n",
        "    # mengubah ke tensor pytorch sehingga nanti siap diproses\n",
        "    features_tensor = torch.tensor(features, dtype=torch.float32)\n",
        "    target_tensor = (\n",
        "        torch.tensor(target.values, dtype=torch.long) if target is not None else None\n",
        "    )\n",
        "\n",
        "    return features_tensor, target_tensor"
      ],
      "metadata": {
        "id": "G7MHgniI6ZGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_target = explore_clean_tensor(\n",
        "    df_train,is_training=True\n",
        ")"
      ],
      "metadata": {
        "id": "uRlORR-P6a5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23fef80-3416-4a0e-c50c-2c35ae86b6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapping column 'Gender' with values: {'Male': 0, 'Female': 1}\n",
            "Mapping column 'Ever_Married' with values: {'No': 0, 'Yes': 1}\n",
            "Mapping column 'Graduated' with values: {'No': 0, 'Yes': 1}\n",
            "Mapping column 'Profession' with values: {'Healthcare': 0, 'Engineer': 1, 'Lawyer': 2, 'Entertainment': 3, 'Artist': 4, 'Executive': 5, 'Doctor': 6, 'Homemaker': 7, 'Marketing': 8}\n",
            "Mapping column 'Spending_Score' with values: {'Low': 0, 'Average': 1, 'High': 2}\n",
            "Mapping column 'Var_1' with values: {'Cat_4': 0, 'Cat_6': 1, 'Cat_7': 2, 'Cat_3': 3, 'Cat_1': 4, 'Cat_2': 5, 'Cat_5': 6}\n",
            "Mapping column 'Segmentation' with values: {'D': 0, 'A': 1, 'B': 2, 'C': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_features, test_target = explore_clean_tensor(\n",
        "    df_test,is_training=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcT8V5Gt6cdw",
        "outputId": "de518327-2edf-46ca-c602-533a6e7374ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapping column 'Gender' with values: {'Female': 0, 'Male': 1}\n",
            "Mapping column 'Ever_Married' with values: {'Yes': 0, 'No': 1}\n",
            "Mapping column 'Graduated' with values: {'Yes': 0, 'No': 1}\n",
            "Mapping column 'Profession' with values: {'Engineer': 0, 'Healthcare': 1, 'Artist': 2, 'Executive': 3, 'Marketing': 4, 'Doctor': 5, 'Lawyer': 6, 'Entertainment': 7, 'Homemaker': 8}\n",
            "Mapping column 'Spending_Score' with values: {'Low': 0, 'Average': 1, 'High': 2}\n",
            "Mapping column 'Var_1' with values: {'Cat_6': 0, 'Cat_4': 1, 'Cat_3': 2, 'Cat_1': 3, 'Cat_2': 4, 'Cat_5': 5, 'Cat_7': 6}\n",
            "Mapping column 'Segmentation' with values: {'B': 0, 'A': 1, 'C': 2, 'D': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pembuatan Model"
      ],
      "metadata": {
        "id": "joggS6GU5LLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut ini adalah kode pembuatan model pada tugas lalu:"
      ],
      "metadata": {
        "id": "z1mwib3b66DH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "dg8xI54B6prq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "\n",
        "Xtrain = train_features\n",
        "Ytrain = train_target\n",
        "\n",
        "Xtest = test_features\n",
        "Ytest = test_target"
      ],
      "metadata": {
        "id": "BUjK-nXC6u6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        super().__init__()\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]"
      ],
      "metadata": {
        "id": "Rb1LZFni6xra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merujuk pada rencana awal tugas besar, kami tidak memiliki dataset untuk validation. Oleh karena itu, kami akan membagi kembali data train dengan perbandingan 80% untuk train, dan 20% validation."
      ],
      "metadata": {
        "id": "LoGTZmtd62wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(Xtrain, Ytrain, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "rRNa1I8s6nTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = MyDataset(X_train, Y_train)\n",
        "valset = MyDataset(X_val, Y_val)\n",
        "testset = MyDataset(Xtest, Ytest)"
      ],
      "metadata": {
        "id": "riZ2_iVT6rSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size, shuffle=True)\n",
        "valloader = DataLoader(valset, batch_size)\n",
        "testloader = DataLoader(testset, batch_size)"
      ],
      "metadata": {
        "id": "yUi9ojkQ7Gtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(10, 32)\n",
        "        self.layer2 = nn.Linear(32, 64)\n",
        "        self.layer3 = nn.Linear(64, 64)\n",
        "        self.layer4 = nn.Linear(64, 64)\n",
        "        self.layer5 = nn.Linear(64, 64)\n",
        "        self.layer6 = nn.Linear(64, 64)\n",
        "        self.layer7 = nn.Linear(64, 64)\n",
        "        self.layer8 = nn.Linear(64, 64)\n",
        "        self.layer9 = nn.Linear(64, 64)\n",
        "        self.layer10 = nn.Linear(64, 64)\n",
        "        self.layer11 = nn.Linear(64, 64)\n",
        "        self.layer12 = nn.Linear(64, 64)\n",
        "        self.layer13= nn.Linear(64, 32)\n",
        "        self.layer14 = nn.Linear(32, 16)\n",
        "        self.layer15 = nn.Linear(16, 4)  # Output layer for 4 classes\n",
        "\n",
        "    # relu for hidden layers bc its simple (making the negative to 0) : sparsity, thurning off some neurons.\n",
        "    # relu is gud bc can mitigate Vanishing Gradient Problem, where the gradient is too low.\n",
        "\n",
        "    # sigmoid = 1/(1/+e^-x). transforms the raw output into a value between 0 and 1, so the res is probabilistic.\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        x = F.relu(self.layer3(x))\n",
        "        x = F.relu(self.layer4(x))\n",
        "        x = F.relu(self.layer5(x))\n",
        "        x = F.relu(self.layer6(x))\n",
        "        x = F.relu(self.layer7(x))\n",
        "        x = F.relu(self.layer8(x))\n",
        "        x = F.relu(self.layer9(x))\n",
        "        x = F.relu(self.layer10(x))\n",
        "        x = F.relu(self.layer11(x))\n",
        "        x = F.relu(self.layer12(x))\n",
        "        x = F.relu(self.layer13(x))\n",
        "        x = F.relu(self.layer14(x))\n",
        "        return F.sigmoid(self.layer15(x))"
      ],
      "metadata": {
        "id": "BBDeSxgX7Ss5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "epoch = 200"
      ],
      "metadata": {
        "id": "uK2rniRo62Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameter Early Stopping"
      ],
      "metadata": {
        "id": "JaElu0FS7Ylb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patience = 100  # jumlah epoch yang diperbolehkan tanpa perbaikan loss validasi sebelum training diberhentikan.\n",
        "best_val_loss = float('inf')  # Nilai awal loss validasi terbaik (tak hingga)\n",
        "best_model_state = None  # Menyimpan model terbaik"
      ],
      "metadata": {
        "id": "WUlqOlG97WoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Sebelumnya: Early Stopping + Adam (weight decay)\n"
      ],
      "metadata": {
        "id": "c2lqPo3a5D_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model ini sudah dicoba pada TB04C sebelumnya"
      ],
      "metadata": {
        "id": "3Js6MHZD5yBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)  # L2 Regularization dengan weight_decay\n",
        "l1_lambda = 0.001  # Koefisien penalti L1"
      ],
      "metadata": {
        "id": "XHXkWSOpBdnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "counter = 0  # Jumlah epoch tanpa perbaikan\n",
        "epoch = 100\n",
        "for ei in range(epoch):\n",
        "     # Training\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for x, y in trainloader:\n",
        "        y = y.long().squeeze()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = loss_fn(output, y)\n",
        "\n",
        "        # Menambahkan penalti L1\n",
        "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
        "        loss += l1_lambda * l1_norm\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(trainloader)\n",
        "\n",
        "    # Validasi\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in valloader:\n",
        "            y = y.long().squeeze()\n",
        "            output = model(x)\n",
        "            val_loss += loss_fn(output, y).item()\n",
        "    avg_train_loss = train_loss\n",
        "    avg_val_loss = val_loss / len(valloader)\n",
        "\n",
        "    print(f\"Epoch={ei + 1}, Avg Train Loss={avg_train_loss:.4f}, Avg Val Loss={avg_val_loss:.4f}\")\n",
        "\n",
        "    # Early stopping:\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0\n",
        "        best_model_state = model.state_dict()\n",
        "    else:\n",
        "        counter += 1\n",
        "    if counter >= patience:\n",
        "        print(f\"Early stopping triggered pada epoch {ei + 1}\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLa93OQSB2Aq",
        "outputId": "3b374bcb-ec2c-41b8-8a70-fd7af44da93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch=1, Avg Train Loss=3.1665, Avg Val Loss=1.3884\n",
            "Epoch=2, Avg Train Loss=1.6735, Avg Val Loss=1.3880\n",
            "Epoch=3, Avg Train Loss=1.4109, Avg Val Loss=1.3877\n",
            "Epoch=4, Avg Train Loss=1.3960, Avg Val Loss=1.3873\n",
            "Epoch=5, Avg Train Loss=1.3909, Avg Val Loss=1.3870\n",
            "Epoch=6, Avg Train Loss=1.3897, Avg Val Loss=1.3867\n",
            "Epoch=7, Avg Train Loss=1.3893, Avg Val Loss=1.3865\n",
            "Epoch=8, Avg Train Loss=1.3890, Avg Val Loss=1.3862\n",
            "Epoch=9, Avg Train Loss=1.3886, Avg Val Loss=1.3860\n",
            "Epoch=10, Avg Train Loss=1.3884, Avg Val Loss=1.3858\n",
            "Epoch=11, Avg Train Loss=1.3882, Avg Val Loss=1.3856\n",
            "Epoch=12, Avg Train Loss=1.3881, Avg Val Loss=1.3855\n",
            "Epoch=13, Avg Train Loss=1.3879, Avg Val Loss=1.3853\n",
            "Epoch=14, Avg Train Loss=1.3878, Avg Val Loss=1.3852\n",
            "Epoch=15, Avg Train Loss=1.3876, Avg Val Loss=1.3851\n",
            "Epoch=16, Avg Train Loss=1.3875, Avg Val Loss=1.3850\n",
            "Epoch=17, Avg Train Loss=1.3874, Avg Val Loss=1.3849\n",
            "Epoch=18, Avg Train Loss=1.3872, Avg Val Loss=1.3848\n",
            "Epoch=19, Avg Train Loss=1.3872, Avg Val Loss=1.3847\n",
            "Epoch=20, Avg Train Loss=1.3871, Avg Val Loss=1.3847\n",
            "Epoch=21, Avg Train Loss=1.3870, Avg Val Loss=1.3846\n",
            "Epoch=22, Avg Train Loss=1.3868, Avg Val Loss=1.3846\n",
            "Epoch=23, Avg Train Loss=1.3868, Avg Val Loss=1.3845\n",
            "Epoch=24, Avg Train Loss=1.3867, Avg Val Loss=1.3845\n",
            "Epoch=25, Avg Train Loss=1.3866, Avg Val Loss=1.3844\n",
            "Epoch=26, Avg Train Loss=1.3865, Avg Val Loss=1.3843\n",
            "Epoch=27, Avg Train Loss=1.3864, Avg Val Loss=1.3843\n",
            "Epoch=28, Avg Train Loss=1.3863, Avg Val Loss=1.3842\n",
            "Epoch=29, Avg Train Loss=1.3862, Avg Val Loss=1.3842\n",
            "Epoch=30, Avg Train Loss=1.3862, Avg Val Loss=1.3841\n",
            "Epoch=31, Avg Train Loss=1.3861, Avg Val Loss=1.3841\n",
            "Epoch=32, Avg Train Loss=1.3861, Avg Val Loss=1.3840\n",
            "Epoch=33, Avg Train Loss=1.3860, Avg Val Loss=1.3840\n",
            "Epoch=34, Avg Train Loss=1.3859, Avg Val Loss=1.3839\n",
            "Epoch=35, Avg Train Loss=1.3859, Avg Val Loss=1.3838\n",
            "Epoch=36, Avg Train Loss=1.3859, Avg Val Loss=1.3838\n",
            "Epoch=37, Avg Train Loss=1.3858, Avg Val Loss=1.3837\n",
            "Epoch=38, Avg Train Loss=1.3858, Avg Val Loss=1.3837\n",
            "Epoch=39, Avg Train Loss=1.3858, Avg Val Loss=1.3836\n",
            "Epoch=40, Avg Train Loss=1.3857, Avg Val Loss=1.3836\n",
            "Epoch=41, Avg Train Loss=1.3857, Avg Val Loss=1.3836\n",
            "Epoch=42, Avg Train Loss=1.3857, Avg Val Loss=1.3835\n",
            "Epoch=43, Avg Train Loss=1.3857, Avg Val Loss=1.3835\n",
            "Epoch=44, Avg Train Loss=1.3856, Avg Val Loss=1.3835\n",
            "Epoch=45, Avg Train Loss=1.3856, Avg Val Loss=1.3834\n",
            "Epoch=46, Avg Train Loss=1.3856, Avg Val Loss=1.3834\n",
            "Epoch=47, Avg Train Loss=1.3856, Avg Val Loss=1.3833\n",
            "Epoch=48, Avg Train Loss=1.3856, Avg Val Loss=1.3833\n",
            "Epoch=49, Avg Train Loss=1.3856, Avg Val Loss=1.3833\n",
            "Epoch=50, Avg Train Loss=1.3856, Avg Val Loss=1.3833\n",
            "Epoch=51, Avg Train Loss=1.3856, Avg Val Loss=1.3832\n",
            "Epoch=52, Avg Train Loss=1.3855, Avg Val Loss=1.3832\n",
            "Epoch=53, Avg Train Loss=1.3855, Avg Val Loss=1.3832\n",
            "Epoch=54, Avg Train Loss=1.3855, Avg Val Loss=1.3832\n",
            "Epoch=55, Avg Train Loss=1.3855, Avg Val Loss=1.3831\n",
            "Epoch=56, Avg Train Loss=1.3855, Avg Val Loss=1.3831\n",
            "Epoch=57, Avg Train Loss=1.3855, Avg Val Loss=1.3831\n",
            "Epoch=58, Avg Train Loss=1.3855, Avg Val Loss=1.3831\n",
            "Epoch=59, Avg Train Loss=1.3854, Avg Val Loss=1.3830\n",
            "Epoch=60, Avg Train Loss=1.3855, Avg Val Loss=1.3830\n",
            "Epoch=61, Avg Train Loss=1.3854, Avg Val Loss=1.3830\n",
            "Epoch=62, Avg Train Loss=1.3855, Avg Val Loss=1.3830\n",
            "Epoch=63, Avg Train Loss=1.3854, Avg Val Loss=1.3830\n",
            "Epoch=64, Avg Train Loss=1.3854, Avg Val Loss=1.3830\n",
            "Epoch=65, Avg Train Loss=1.3854, Avg Val Loss=1.3829\n",
            "Epoch=66, Avg Train Loss=1.3854, Avg Val Loss=1.3829\n",
            "Epoch=67, Avg Train Loss=1.3854, Avg Val Loss=1.3829\n",
            "Epoch=68, Avg Train Loss=1.3854, Avg Val Loss=1.3829\n",
            "Epoch=69, Avg Train Loss=1.3854, Avg Val Loss=1.3829\n",
            "Epoch=70, Avg Train Loss=1.3853, Avg Val Loss=1.3829\n",
            "Epoch=71, Avg Train Loss=1.3854, Avg Val Loss=1.3829\n",
            "Epoch=72, Avg Train Loss=1.3854, Avg Val Loss=1.3829\n",
            "Epoch=73, Avg Train Loss=1.3853, Avg Val Loss=1.3828\n",
            "Epoch=74, Avg Train Loss=1.3853, Avg Val Loss=1.3828\n",
            "Epoch=75, Avg Train Loss=1.3854, Avg Val Loss=1.3828\n",
            "Epoch=76, Avg Train Loss=1.3853, Avg Val Loss=1.3828\n",
            "Epoch=77, Avg Train Loss=1.3854, Avg Val Loss=1.3828\n",
            "Epoch=78, Avg Train Loss=1.3853, Avg Val Loss=1.3828\n",
            "Epoch=79, Avg Train Loss=1.3853, Avg Val Loss=1.3828\n",
            "Epoch=80, Avg Train Loss=1.3853, Avg Val Loss=1.3828\n",
            "Epoch=81, Avg Train Loss=1.3853, Avg Val Loss=1.3828\n",
            "Epoch=82, Avg Train Loss=1.3853, Avg Val Loss=1.3828\n",
            "Epoch=83, Avg Train Loss=1.3853, Avg Val Loss=1.3828\n",
            "Epoch=84, Avg Train Loss=1.3853, Avg Val Loss=1.3827\n",
            "Epoch=85, Avg Train Loss=1.3853, Avg Val Loss=1.3827\n",
            "Epoch=86, Avg Train Loss=1.3853, Avg Val Loss=1.3827\n",
            "Epoch=87, Avg Train Loss=1.3853, Avg Val Loss=1.3827\n",
            "Epoch=88, Avg Train Loss=1.3853, Avg Val Loss=1.3827\n",
            "Epoch=89, Avg Train Loss=1.3853, Avg Val Loss=1.3827\n",
            "Epoch=90, Avg Train Loss=1.3853, Avg Val Loss=1.3827\n",
            "Epoch=91, Avg Train Loss=1.3853, Avg Val Loss=1.3827\n",
            "Epoch=92, Avg Train Loss=1.3853, Avg Val Loss=1.3827\n",
            "Epoch=93, Avg Train Loss=1.3852, Avg Val Loss=1.3827\n",
            "Epoch=94, Avg Train Loss=1.3853, Avg Val Loss=1.3827\n",
            "Epoch=95, Avg Train Loss=1.3853, Avg Val Loss=1.3827\n",
            "Epoch=96, Avg Train Loss=1.3852, Avg Val Loss=1.3826\n",
            "Epoch=97, Avg Train Loss=1.3853, Avg Val Loss=1.3826\n",
            "Epoch=98, Avg Train Loss=1.3852, Avg Val Loss=1.3826\n",
            "Epoch=99, Avg Train Loss=1.3852, Avg Val Loss=1.3826\n",
            "Epoch=100, Avg Train Loss=1.3853, Avg Val Loss=1.3826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if best_model_state:\n",
        "    model.load_state_dict(best_model_state)"
      ],
      "metadata": {
        "id": "Yh9hhS-kBs_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi pada data test\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    ncorrect = 0\n",
        "    test_loss = 0.0\n",
        "    for x, y in testloader:\n",
        "        y = y.long().squeeze()\n",
        "        yt = model(x)\n",
        "        test_loss += loss_fn(yt, y).item()\n",
        "        preds = torch.argmax(yt, dim=1)\n",
        "        ncorrect += (preds == y).sum().item()\n",
        "\n",
        "    avg_test_acc = ncorrect / len(test_features) * 100.0\n",
        "    avg_test_loss = test_loss / len(testloader)\n",
        "\n",
        "print(\"Final Test Results\")\n",
        "print(f'Avg Test Loss={avg_test_loss:.4f}')\n",
        "print(f'Avg Test Acc={avg_test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rFV2HSgBtTx",
        "outputId": "b484e277-5129-4213-e25c-6f910f1405c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Results\n",
            "Avg Test Loss=1.3875\n",
            "Avg Test Acc=20.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternatif 1: Early Stopping + RMS Prop\n"
      ],
      "metadata": {
        "id": "jVd4z5vN4_k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "best_model_state = None\n",
        "counter = 0  # Untuk early stopping"
      ],
      "metadata": {
        "id": "FTMUwYqm36k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSprop adalah algoritma optimasi yang menjaga stabilitas pembaruan parameter dengan menormalisasi gradien menggunakan rata-rata eksponensial dari kuadrat gradien. Kode dibawah ini memiliki parameter alpha=0.99 menjaga agar rata-rata gradien kuadrat tetap stabil, eps=1e-8 mencegah error akibat pembagian nol, weight_decay=0.0001 menambahkan penalti pada bobot besar untuk mencegah overfitting, dan momentum=0.9 membantu model lebih cepat mencapai hasil optimal dengan mempertahankan arah pembaruan sebelumnya."
      ],
      "metadata": {
        "id": "-n91__jzDeTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.RMSprop(model.parameters(), lr=0.0001, alpha=0.99, eps=1e-8, weight_decay=0.0001, momentum=0.9)\n",
        "# momentum mempengaruhi influence nilai sebelumnya, mepeprcepat pelatihan... 0,9 = 90% gradien sebelumnya\n",
        "# alpha  faktor peluruhan eksponensial\n",
        "\n"
      ],
      "metadata": {
        "id": "5FYu381R14t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 100\n",
        "for ei in range(epoch):\n",
        "    # Training\n",
        "    model.train()\n",
        "    sum_loss = 0.0\n",
        "    for x, y in trainloader:\n",
        "        y = y.long().squeeze()\n",
        "        optimizer.zero_grad()\n",
        "        yt = model(x)\n",
        "        loss = loss_fn(yt, y)\n",
        "        sum_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    avg_train_loss = sum_loss / len(trainloader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in valloader:\n",
        "            y = y.long().squeeze()\n",
        "            yt = model(x)\n",
        "            val_loss += loss_fn(yt, y).item()\n",
        "    avg_val_loss = val_loss / len(valloader)\n",
        "\n",
        "    print(f\"Epoch={ei + 1}, Avg Train Loss={avg_train_loss:.4f}, Avg Val Loss={avg_val_loss:.4f}\")\n",
        "\n",
        "    # Early stopping:\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        counter = 0\n",
        "        best_model_state = model.state_dict()\n",
        "    else:\n",
        "        counter += 1\n",
        "    if counter >= patience:\n",
        "        print(f\"Early stopping triggered pada epoch {ei + 1}\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPpgW2Xb7QqG",
        "outputId": "3f1eaf40-008d-4bb2-ee9a-cd6e4d79a977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch=1, Avg Train Loss=1.3841, Avg Val Loss=1.3821\n",
            "Epoch=2, Avg Train Loss=1.3841, Avg Val Loss=1.3821\n",
            "Epoch=3, Avg Train Loss=1.3841, Avg Val Loss=1.3820\n",
            "Epoch=4, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=5, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=6, Avg Train Loss=1.3841, Avg Val Loss=1.3820\n",
            "Epoch=7, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=8, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=9, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=10, Avg Train Loss=1.3841, Avg Val Loss=1.3820\n",
            "Epoch=11, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=12, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=13, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=14, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=15, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=16, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=17, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=18, Avg Train Loss=1.3841, Avg Val Loss=1.3819\n",
            "Epoch=19, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=20, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=21, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=22, Avg Train Loss=1.3841, Avg Val Loss=1.3820\n",
            "Epoch=23, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=24, Avg Train Loss=1.3841, Avg Val Loss=1.3819\n",
            "Epoch=25, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=26, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=27, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=28, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=29, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=30, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=31, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=32, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=33, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=34, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=35, Avg Train Loss=1.3841, Avg Val Loss=1.3820\n",
            "Epoch=36, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=37, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=38, Avg Train Loss=1.3841, Avg Val Loss=1.3820\n",
            "Epoch=39, Avg Train Loss=1.3841, Avg Val Loss=1.3820\n",
            "Epoch=40, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=41, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=42, Avg Train Loss=1.3841, Avg Val Loss=1.3820\n",
            "Epoch=43, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=44, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=45, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=46, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=47, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=48, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=49, Avg Train Loss=1.3841, Avg Val Loss=1.3820\n",
            "Epoch=50, Avg Train Loss=1.3841, Avg Val Loss=1.3819\n",
            "Epoch=51, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=52, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=53, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=54, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=55, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=56, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=57, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=58, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=59, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=60, Avg Train Loss=1.3841, Avg Val Loss=1.3819\n",
            "Epoch=61, Avg Train Loss=1.3841, Avg Val Loss=1.3819\n",
            "Epoch=62, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=63, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=64, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=65, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=66, Avg Train Loss=1.3841, Avg Val Loss=1.3819\n",
            "Epoch=67, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=68, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=69, Avg Train Loss=1.3841, Avg Val Loss=1.3820\n",
            "Epoch=70, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=71, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=72, Avg Train Loss=1.3841, Avg Val Loss=1.3820\n",
            "Epoch=73, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=74, Avg Train Loss=1.3841, Avg Val Loss=1.3819\n",
            "Epoch=75, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=76, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=77, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=78, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=79, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=80, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=81, Avg Train Loss=1.3841, Avg Val Loss=1.3820\n",
            "Epoch=82, Avg Train Loss=1.3841, Avg Val Loss=1.3820\n",
            "Epoch=83, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=84, Avg Train Loss=1.3841, Avg Val Loss=1.3820\n",
            "Epoch=85, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=86, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=87, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=88, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=89, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=90, Avg Train Loss=1.3841, Avg Val Loss=1.3819\n",
            "Epoch=91, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=92, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=93, Avg Train Loss=1.3841, Avg Val Loss=1.3819\n",
            "Epoch=94, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=95, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=96, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=97, Avg Train Loss=1.3841, Avg Val Loss=1.3819\n",
            "Epoch=98, Avg Train Loss=1.3840, Avg Val Loss=1.3820\n",
            "Epoch=99, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=100, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if best_model_state:\n",
        "    model.load_state_dict(best_model_state)"
      ],
      "metadata": {
        "id": "7p4KN7qP7me-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi pada data test\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    ncorrect = 0\n",
        "    test_loss = 0.0\n",
        "    for x, y in testloader:\n",
        "        y = y.long().squeeze()\n",
        "        yt = model(x)\n",
        "        test_loss += loss_fn(yt, y).item()\n",
        "        preds = torch.argmax(yt, dim=1)\n",
        "        ncorrect += (preds == y).sum().item()\n",
        "\n",
        "    avg_test_acc = ncorrect / len(test_features) * 100.0\n",
        "    avg_test_loss = test_loss / len(testloader)\n",
        "\n",
        "print(\"Final Test Results\")\n",
        "print(f'Avg Test Loss={avg_test_loss:.4f}')\n",
        "print(f'Avg Test Acc={avg_test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHHkrgB87pdE",
        "outputId": "0ddc7ee2-a9e0-408e-d70d-f9f95bef9377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Results\n",
            "Avg Test Loss=1.3893\n",
            "Avg Test Acc=20.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternatif 2: Early Stopping + SGD momentum\n",
        "\n"
      ],
      "metadata": {
        "id": "u8H3xRYr6tQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "best_model_state = None\n",
        "counter = 0  # Untuk early stopping"
      ],
      "metadata": {
        "id": "xAPjYUXK4edR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di bawah ini menggunakan algoritma Stochastic Gradient Descent (SGD) untuk model, dengan parameter learning rate 0.0001, momentum 0.9, dan weight decay (regularisasi) 0.0001. Optimizer ini digunakan untuk memperbarui bobot model selama proses pelatihan dengan memperhitungkan gradien dan parameter lainnya."
      ],
      "metadata": {
        "id": "CqOg8RSPH9at"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.0001)"
      ],
      "metadata": {
        "id": "juOF6_G36tQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 100\n",
        "for ei in range(epoch):\n",
        "    # Training\n",
        "    model.train()\n",
        "    sum_loss = 0.0\n",
        "    for x, y in trainloader:\n",
        "        y = y.long().squeeze()\n",
        "        optimizer.zero_grad()\n",
        "        yt = model(x)\n",
        "        loss = loss_fn(yt, y)\n",
        "        sum_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    avg_train_loss = sum_loss / len(trainloader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in valloader:\n",
        "            y = y.long().squeeze()\n",
        "            yt = model(x)\n",
        "            val_loss += loss_fn(yt, y).item()\n",
        "    avg_val_loss = val_loss / len(valloader)\n",
        "\n",
        "    print(f\"Epoch={ei + 1}, Avg Train Loss={avg_train_loss:.4f}, Avg Val Loss={avg_val_loss:.4f}\")\n",
        "\n",
        "    # Early stopping:\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        counter = 0\n",
        "        best_model_state = model.state_dict()\n",
        "    else:\n",
        "        counter += 1\n",
        "    if counter >= patience:\n",
        "        print(f\"Early stopping triggered pada epoch {ei + 1}\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a2ef6a-ab7f-4543-f317-45903fce686a",
        "id": "NCNHyA_Q6tQ9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch=1, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=2, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=3, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=4, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=5, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=6, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=7, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=8, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=9, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=10, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=11, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=12, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=13, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=14, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=15, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=16, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=17, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=18, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=19, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=20, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=21, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=22, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=23, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=24, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=25, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=26, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=27, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=28, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=29, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=30, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=31, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=32, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=33, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=34, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=35, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=36, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=37, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=38, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=39, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=40, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=41, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=42, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=43, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=44, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=45, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=46, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=47, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=48, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=49, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=50, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=51, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=52, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=53, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=54, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=55, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=56, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=57, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=58, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=59, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=60, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=61, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=62, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=63, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=64, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=65, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=66, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=67, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=68, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=69, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=70, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=71, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=72, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=73, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=74, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=75, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=76, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=77, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=78, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=79, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=80, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=81, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=82, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=83, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=84, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=85, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=86, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=87, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=88, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=89, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=90, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=91, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=92, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=93, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=94, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=95, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=96, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=97, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=98, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n",
            "Epoch=99, Avg Train Loss=1.3840, Avg Val Loss=1.3819\n",
            "Epoch=100, Avg Train Loss=1.3839, Avg Val Loss=1.3819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if best_model_state:\n",
        "    model.load_state_dict(best_model_state)"
      ],
      "metadata": {
        "id": "S8qV5kfZ6tQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi pada data test\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    ncorrect = 0\n",
        "    test_loss = 0.0\n",
        "    for x, y in testloader:\n",
        "        y = y.long().squeeze()\n",
        "        yt = model(x)\n",
        "        test_loss += loss_fn(yt, y).item()\n",
        "        preds = torch.argmax(yt, dim=1)\n",
        "        ncorrect += (preds == y).sum().item()\n",
        "\n",
        "    avg_test_acc = ncorrect / len(test_features) * 100.0\n",
        "    avg_test_loss = test_loss / len(testloader)\n",
        "\n",
        "print(\"Final Test Results\")\n",
        "print(f'Avg Test Loss={avg_test_loss:.4f}')\n",
        "print(f'Avg Test Acc={avg_test_acc:.2f}%')"
      ],
      "metadata": {
        "id": "e00u8bZ56tQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b433500-2649-4556-ca98-29bb6bdc5fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Results\n",
            "Avg Test Loss=1.3893\n",
            "Avg Test Acc=20.94%\n"
          ]
        }
      ]
    }
  ]
}